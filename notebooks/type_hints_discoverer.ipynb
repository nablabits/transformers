{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bd7a7338e5bf96",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 07:28:45.358851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from inspect import getfullargspec\n",
    "from typing import get_type_hints\n",
    "from transformers import TFAlbertPreTrainedModel, TFBlipTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689350a9b05d5309",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'inputs', 'training', 'mask'], varargs=None, varkw=None, defaults=(None, None), kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getfullargspec(TFAlbertPreTrainedModel.call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f5c4bf-2f16-414f-9ec3-78b89bf31ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'config', 'add_pooling_layer', 'name'], varargs=None, varkw='kwargs', defaults=(True, None), kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getfullargspec(TFBlipTextModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719d1a51-bc62-431a-ad83-f11bb0ad81de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "issubclass(TFAlbertPreTrainedModel, transformers.TFPreTrainedModel)\n",
    "\n",
    "import inspect\n",
    "\n",
    "def is_method_overridden(cls, method_name):\n",
    "    return method_name in cls.__dict__ and inspect.isfunction(cls.__dict__[method_name])\n",
    "\n",
    "\n",
    "print(is_method_overridden(TFAlbertPreTrainedModel, \"call\"))\n",
    "print(is_method_overridden(TFBlipTextModel, \"call\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4593f90a54fc1f7f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T04:48:39.781312147Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigBirdForQuestionAnswering: {'question_lengths'}\n",
      "Blip2QFormerModel: {'output_attentions', 'use_cache', 'encoder_hidden_states', 'past_key_values', 'attention_mask', 'return_dict', 'query_embeds', 'encoder_attention_mask', 'head_mask', 'output_hidden_states', 'return'}\n",
      "ConditionalDetrForObjectDetection: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "ConditionalDetrForSegmentation: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "ConditionalDetrModel: {'decoder_inputs_embeds', 'output_attentions', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "CpmAntModel: {'return'}\n",
      "DPRContextEncoder: {'output_attentions', 'output_hidden_states', 'return_dict'}\n",
      "DPRQuestionEncoder: {'output_attentions', 'output_hidden_states', 'return_dict'}\n",
      "DPRReader: {'return_dict'}\n",
      "DecisionTransformerModel: {'actions', 'output_attentions', 'attention_mask', 'rewards', 'timesteps', 'states', 'return_dict', 'output_hidden_states', 'returns_to_go'}\n",
      "DeformableDetrForObjectDetection: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DeformableDetrModel: {'decoder_inputs_embeds', 'output_attentions', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DetaForObjectDetection: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DetaModel: {'decoder_inputs_embeds', 'output_attentions', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DetrForObjectDetection: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DetrForSegmentation: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DetrModel: {'decoder_inputs_embeds', 'output_attentions', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "ErnieMForInformationExtraction: {'return'}\n",
      "ErnieMForMultipleChoice: {'return'}\n",
      "ErnieMForQuestionAnswering: {'return'}\n",
      "ErnieMForSequenceClassification: {'return'}\n",
      "ErnieMForTokenClassification: {'return'}\n",
      "ErnieMModel: {'return'}\n",
      "EsmForProteinFolding: {'return'}\n",
      "GraphormerModel: {'perturb', 'masked_tokens'}\n",
      "InstructBlipQFormerModel: {'output_attentions', 'use_cache', 'encoder_hidden_states', 'past_key_values', 'attention_mask', 'position_ids', 'input_ids', 'return_dict', 'query_embeds', 'encoder_attention_mask', 'head_mask', 'output_hidden_states', 'return'}\n",
      "LayoutLMForMaskedLM: {'encoder_attention_mask', 'encoder_hidden_states'}\n",
      "LukeForEntitySpanClassification: {'attention_mask'}\n",
      "MgpstrForSceneTextRecognition: {'output_attentions', 'return_dict', 'pixel_values', 'output_hidden_states', 'output_a3_attentions', 'return'}\n",
      "MgpstrModel: {'output_attentions', 'return_dict', 'pixel_values', 'output_hidden_states', 'return'}\n",
      "PLBartForConditionalGeneration: {'decoder_inputs_embeds'}\n",
      "PLBartModel: {'decoder_inputs_embeds'}\n",
      "Pix2StructTextModel: {'inputs_embeds', 'output_attentions', 'use_cache', 'encoder_hidden_states', 'past_key_values', 'labels', 'attention_mask', 'cross_attn_head_mask', 'input_ids', 'return_dict', 'encoder_attention_mask', 'head_mask', 'output_hidden_states', 'return'}\n",
      "RagModel: {'context_attention_mask'}\n",
      "SamModel: {'return_dict'}\n",
      "Swin2SRModel: {'pixel_values'}\n",
      "TableTransformerForObjectDetection: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "TableTransformerModel: {'decoder_inputs_embeds', 'output_attentions', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "TimesformerModel: {'output_attentions', 'return_dict', 'pixel_values', 'output_hidden_states', 'return'}\n",
      "TimmBackbone: {'output_attentions', 'return_dict', 'output_hidden_states', 'pixel_values'}\n",
      "TvltForAudioVisualClassification: {'output_attentions', 'labels', 'audio_values', 'pixel_values', 'audio_mask', 'pixel_mask', 'return_dict', 'output_hidden_states'}\n",
      "TvltForPreTraining: {'pixel_values_mixed', 'output_attentions', 'labels', 'audio_values', 'pixel_values', 'audio_mask', 'pixel_mask_mixed', 'pixel_mask', 'return_dict', 'output_hidden_states'}\n",
      "TvltModel: {'output_attentions', 'audio_values', 'pixel_values', 'audio_mask', 'mask_audio', 'mask_pixel', 'pixel_mask', 'return_dict', 'output_hidden_states'}\n",
      "VivitForVideoClassification: {'output_attentions', 'labels', 'return_dict', 'pixel_values', 'head_mask', 'output_hidden_states', 'return'}\n",
      "VivitModel: {'output_attentions', 'return_dict', 'pixel_values', 'head_mask', 'output_hidden_states', 'return'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_missing_hints(model):\n",
    "\tif issubclass(model, transformers.PreTrainedModel):\n",
    "\t\tactual_hints = set(get_type_hints(model.forward))\n",
    "\t\texpected_hints = set(getfullargspec(model.forward).args)\n",
    "\t\texpected_hints.remove('self')  # self does not carry type hints\n",
    "\t\texpected_hints.add('return')  # we need a type hint also for the output\n",
    "\n",
    "\t\tmissing_hints = expected_hints - actual_hints\n",
    "\t\tif missing_hints:\n",
    "\t\t\tprint(f\"{obj}: {missing_hints}\")\n",
    "\n",
    "\n",
    "for obj in dir(transformers):\n",
    "\ttry:\n",
    "\t\tmodel = getattr(transformers, obj)\n",
    "\t\tcompute_missing_hints(model)\n",
    "\texcept:\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca772803a1e6269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T04:56:32.864273079Z",
     "start_time": "2023-08-15T04:56:32.817309341Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeformableDetrDecoder: {'output_attentions', 'encoder_hidden_states', 'position_embeddings', 'reference_points', 'spatial_shapes', 'return_dict', 'valid_ratios', 'encoder_attention_mask', 'inputs_embeds', 'output_hidden_states', 'level_start_index', 'return'}\n",
      "DeformableDetrEncoder: {'output_attentions', 'attention_mask', 'position_embeddings', 'spatial_shapes', 'return_dict', 'valid_ratios', 'inputs_embeds', 'output_hidden_states', 'level_start_index', 'return'}\n",
      "DeformableDetrForObjectDetection: {'decoder_inputs_embeds', 'output_attentions', 'labels', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n",
      "DeformableDetrModel: {'decoder_inputs_embeds', 'output_attentions', 'pixel_values', 'decoder_attention_mask', 'encoder_outputs', 'pixel_mask', 'return_dict', 'inputs_embeds', 'output_hidden_states', 'return'}\n"
     ]
    }
   ],
   "source": [
    "# type hints checker as per module\n",
    "\n",
    "from transformers.models.deformable_detr import modeling_deformable_detr\n",
    "for obj in dir(modeling_deformable_detr):\n",
    "\ttry:\n",
    "\t\tmodel = getattr(modeling_deformable_detr, obj)\n",
    "\t\tcompute_missing_hints(model)\n",
    "\texcept:\n",
    "\t\tcontinue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
